experiment:
  name: "lite_hadamard"
  description: "Lite Model with Hadamard Mixing (width=1.0)"
  version: "v1.1"

paths:
  coco_root: "dataset/coco_train2017/"
  checkpoint_dir: "checkpoints/lite_hadamard"
  log_dir: "logs/"
  superpoint_weights: "dataset/superpoint_v1.pth" 

system:
  device: "cuda"
  num_workers: 8
  seed: 42

model:
  teacher: "alike"
  alike_model: "alike-t"
  descriptor_dim: 64
  width_mult: 1.0
  use_depthwise: true
  use_hadamard: true
  
training:
  batch_size: 4
  gradient_accumulation_steps: 2  # Effective batch = 4 * 2 = 8
  epochs: 15
  n_steps: 320000
  lr: 0.0003
  save_interval: 5000
  
  loss_weights:
    heatmap: 1.0   
    distill: 1.0    
    fine: 1.0
    reliability: 1.0

  scheduler:
    conf_thresh:
      start_val: 0.0
      end_val: 0.15
      start_pct: 0.0
      end_pct: 0.5

visualization:
  colormap: "hot"

augmentation:
  warp_resolution: [640, 480]  
  out_resolution: [640, 480]   
  sides_crop: 0.1              
  photometric: true            
  geometric: true              
  use_tps: true                
  tps_prob: 0.5                
  difficulty: 0.3

# Evaluation during training
evaluation:
  enabled: true
  interval: 50000  # Evaluate every 50k steps
  image_dir: "dataset/megadepth_test_1500"
  json_path: "assets/megadepth_1500.json"
  num_pairs: 100  # Subset for speed
  top_k: 2000
